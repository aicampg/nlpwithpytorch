{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "careful-florence",
   "metadata": {
    "id": "light-portal"
   },
   "source": [
    "# Classifying Food Reviews\n",
    "\n",
    "Data __Amazon Food Reviews__\n",
    "* We are using a transformed version of this 500k dataset\n",
    "* Reference: https://snap.stanford.edu/data/web-FineFoods.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-beginning",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "limiting-hearts",
    "outputId": "dbf2273c-5c85-41e0-b703-1c56840a5b69"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-binary",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujtWxERIjONP",
    "outputId": "cef8c71e-0c77-4234-93f9-6c5e70424487"
   },
   "outputs": [],
   "source": [
    "# Run this if you do not already have Reviews.csv downloaded\r\n",
    "!wget https://www.dropbox.com/s/fxtgg2v2r8lua01/Reviews.csv?dl=0 -O Reviews.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-transaction",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5xRnO-LjVwV",
    "outputId": "23fc0f1a-f2ad-4741-8dc7-d4f988c2b4fd"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-marina",
   "metadata": {
    "id": "brave-bernard"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-there",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "flying-death",
    "outputId": "49f3d283-39d9-4ecf-dcdc-30731a2d9997"
   },
   "outputs": [],
   "source": [
    "food_reviews_df=pd.read_csv('Reviews.csv')\n",
    "food_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-silicon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "incoming-palestine",
    "outputId": "a83b48fc-86a5-435c-92f6-7cc9ebe40175"
   },
   "outputs": [],
   "source": [
    "food_reviews_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-manor",
   "metadata": {
    "id": "hollow-building"
   },
   "outputs": [],
   "source": [
    "food_reviews_df = food_reviews_df[['Text', 'Score']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-hunger",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "offensive-praise",
    "outputId": "9c73951b-bf1a-4c52-937a-2fde16af9a22"
   },
   "outputs": [],
   "source": [
    "ax=food_reviews_df.Score.value_counts().plot(kind='bar')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"score.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-evaluation",
   "metadata": {
    "id": "changed-helmet"
   },
   "outputs": [],
   "source": [
    "food_reviews_df.loc[food_reviews_df.Score <= 3, \"Score\"] = 0\n",
    "food_reviews_df.loc[food_reviews_df.Score >= 4, \"Score\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-exchange",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "fundamental-adapter",
    "outputId": "1aa60b5d-0746-4f0d-d6e3-e2abf36fcfdf"
   },
   "outputs": [],
   "source": [
    "ax=food_reviews_df.Score.value_counts().plot(kind='bar')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"score_boolean.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-carpet",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "genetic-cliff",
    "outputId": "e19c3b5f-2e42-499b-f50f-1d10cbe26f5b"
   },
   "outputs": [],
   "source": [
    "food_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-stock",
   "metadata": {
    "id": "upset-studio"
   },
   "outputs": [],
   "source": [
    "train_pos_df=food_reviews_df[food_reviews_df.Score==1][:5000]\n",
    "train_neg_df=food_reviews_df[food_reviews_df.Score==0][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-continuity",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dedicated-updating",
    "outputId": "7c69d222-21c2-45cd-ccfe-7153363f2485"
   },
   "outputs": [],
   "source": [
    "train_df=train_pos_df.append(train_neg_df)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-makeup",
   "metadata": {
    "id": "shaped-actor"
   },
   "source": [
    "## Pre-Processing\n",
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-blocking",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "entire-charm",
    "outputId": "24524e0e-a14a-47f6-8448-4ecbcb8f37e6"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # create nlp object for English\n",
    "sample_review = food_reviews_df.Text[101]\n",
    "sample_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-handy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hispanic-amber",
    "outputId": "ba53dee5-1ac5-40e2-f7df-4f51ebf7cffd"
   },
   "outputs": [],
   "source": [
    "parsed_review = nlp(sample_review)\n",
    "parsed_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-washer",
   "metadata": {
    "id": "colonial-frequency"
   },
   "source": [
    "## Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-waste",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "operating-conducting",
    "outputId": "7b134f3f-2b2b-4dff-b0f1-5e12162c54a5"
   },
   "outputs": [],
   "source": [
    "tokenized_text = pd.DataFrame()\n",
    "\n",
    "for i, token in enumerate(parsed_review):\n",
    "    tokenized_text.loc[i, 'text'] = token.text\n",
    "    tokenized_text.loc[i, 'lemma'] = token.lemma_,\n",
    "    tokenized_text.loc[i, 'pos'] = token.pos_\n",
    "    tokenized_text.loc[i, 'tag'] = token.tag_\n",
    "    tokenized_text.loc[i, 'dep'] = token.dep_\n",
    "    tokenized_text.loc[i, 'shape'] = token.shape_\n",
    "    tokenized_text.loc[i, 'is_alpha'] = token.is_alpha\n",
    "    tokenized_text.loc[i, 'is_stop'] = token.is_stop\n",
    "    tokenized_text.loc[i, 'is_punctuation'] = token.is_punct\n",
    "\n",
    "tokenized_text[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-pollution",
   "metadata": {
    "id": "peaceful-offense"
   },
   "source": [
    "## Named Entity Recognition (NER)\n",
    "\n",
    "| Type        | Description                                          |\n",
    "| :---------- | :--------------------------------------------------- |\n",
    "| PERSON      | People, including fictional.                         |\n",
    "| NORP        | Nationalities or religious or political groups.      |\n",
    "| FAC         | Buildings, airports, highways, bridges, etc.         |\n",
    "| ORG         | Companies, agencies, institutions, etc.              |\n",
    "| GPE         | Countries, cities, states.                           |\n",
    "| LOC         | Non-GPE locations, mountain ranges, bodies of water. |\n",
    "| PRODUCT     | Objects, vehicles, foods, etc. (Not services.)       |\n",
    "| EVENT       | Named hurricanes, battles, wars, sports events, etc. |\n",
    "| WORK_OF_ART | Titles of books, songs, etc.                         |\n",
    "| LAW         | Named documents made into laws.                      |\n",
    "| LANGUAGE    | Any named language.                                  |\n",
    "| DATE        | Absolute or relative dates or periods.               |\n",
    "| TIME        | Times smaller than a day.                            |\n",
    "| PERCENT     | Percentage, including \"%\".                           |\n",
    "| MONEY       | Monetary values, including unit.                     |\n",
    "| QUANTITY    | Measurements, as of weight or distance.              |\n",
    "| ORDINAL     | \"first\", \"second\", etc.                              |\n",
    "| CARDINAL    | Numerals that do not fall under another type         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-crystal",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "joint-worse",
    "outputId": "3f5b65b7-1abc-4019-9309-4ae6ec7ab76a"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(parsed_review, style='dep', jupyter=True, options={'distance': 90})\n",
    "# use spacy.explain('tag') if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-arbitration",
   "metadata": {
    "id": "academic-guyana"
   },
   "source": [
    "## Dependency parsing\n",
    "\n",
    "Identifies sentences, assigning a syntactic structure to it (subject-object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-tackle",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiscal-corrections",
    "outputId": "2261b54a-91b0-4b61-acfa-09c1c7cf9d52"
   },
   "outputs": [],
   "source": [
    "sentence_spans = list(parsed_review.sents)\n",
    "sentence_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-directive",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "champion-equipment",
    "outputId": "2b77bc8a-edd2-4cbd-d4b5-a930028f423f"
   },
   "outputs": [],
   "source": [
    "options = {'compact': True, 'bg': 'white','distance': 80,\n",
    "           'color': 'green', 'font': 'Arial'}\n",
    "displacy.render(parsed_review, jupyter=True, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-marriage",
   "metadata": {
    "id": "focal-airplane"
   },
   "source": [
    "## Processing noun chunks \n",
    "\n",
    "The dependency parser adds the `token.dep` and `token.head` attributes\n",
    "Further, it is also responsible for **noun chunks**: detecting sentences and base noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-cameroon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "responsible-interest",
    "outputId": "3d40756e-e3ba-4102-c0df-bce2e7b58cca"
   },
   "outputs": [],
   "source": [
    "noun_chunks_df = pd.DataFrame()\n",
    "\n",
    "for i, chunk in enumerate(parsed_review.noun_chunks):\n",
    "    noun_chunks_df.loc[i, 'text'] = chunk.text\n",
    "    noun_chunks_df.loc[i, 'root'] = chunk.root,\n",
    "    noun_chunks_df.loc[i, 'root.text'] = chunk.root.text,\n",
    "    noun_chunks_df.loc[i, 'root.dep_'] = chunk.root.dep_\n",
    "    noun_chunks_df.loc[i, 'root.head.text'] = chunk.root.head.text\n",
    "\n",
    "noun_chunks_df[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-danger",
   "metadata": {
    "id": "honey-flashing"
   },
   "source": [
    "## Text Classification\n",
    "\n",
    "By default, spaCy's text categorizer uses CNN to assign position sensitive vectors to each word in the document. First, prepare the data spaCy expects, in the form of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-headline",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "marine-checkout",
    "outputId": "155cf186-31e9-4193-cdc2-097e12e5764e"
   },
   "outputs": [],
   "source": [
    "train_df['tuples'] = train_df.apply(\n",
    "    lambda row: (row['Text'],row['Score']), axis=1)\n",
    "train = train_df['tuples'].tolist()\n",
    "train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-progressive",
   "metadata": {
    "id": "improved-twelve"
   },
   "outputs": [],
   "source": [
    "#functions from spacy documentation\n",
    "def load_data(limit=0, split=0.8):\n",
    "    train_data = train\n",
    "    np.random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{'POSITIVE': bool(y)} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 1e-8  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 1e-8  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {'textcat_p': precision, 'textcat_r': recall, 'textcat_f': f_score}\n",
    "\n",
    "#(\"Number of texts to train from\",\"t\" , int)\n",
    "n_texts=3000\n",
    "#You can increase texts count if you have more computational power.\n",
    "\n",
    "#(\"Number of training iterations\", \"n\", int))\n",
    "n_iter=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-stability",
   "metadata": {
    "id": "underlying-sister"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-attempt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "motivated-advance",
    "outputId": "2f9d9d0e-9bc6-4d38-8276-f217c836a9a9"
   },
   "outputs": [],
   "source": [
    "# add the text classifier to the pipeline if it doesn't exist\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'textcat' not in nlp.pipe_names:\n",
    "  textcat = nlp.create_pipe('textcat')\n",
    "  nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "\n",
    "# add label to text classifier\n",
    "textcat.add_label('POSITIVE')\n",
    "\n",
    "# load the dataset\n",
    "print(\"Loading food reviews data...\")\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "      .format(n_texts, len(train_texts), len(dev_texts)))\n",
    "\n",
    "train_data = list(zip(train_texts,\n",
    "                      [{'cats': cats} for cats in train_cats]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-creek",
   "metadata": {
    "id": "approximate-flush"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-layout",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "immediate-motor",
    "outputId": "1b5db3e4-d3af-4109-bb76-7b469db40ce6"
   },
   "outputs": [],
   "source": [
    "# add the text classifier to the pipeline if it doesn't exist\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'textcat' not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe('textcat')\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "\n",
    "# add label to text classifier\n",
    "textcat.add_label('POSITIVE')\n",
    "\n",
    "# load the dataset\n",
    "print(\"Loading food reviews data...\")\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=n_texts)\n",
    "print(\"Using {} examples ({} training, {} evaluation)\"\n",
    "      .format(n_texts, len(train_texts), len(dev_texts)))\n",
    "train_data = list(zip(train_texts,\n",
    "                      [{'cats': cats} for cats in train_cats]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-trust",
   "metadata": {
    "id": "KaHx7-bTleE4"
   },
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-ferry",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zh_sWtpHlqhp",
    "outputId": "93ee909d-b112-4139-f350-39df8ae7e074"
   },
   "outputs": [],
   "source": [
    "# get names of other pipes to disable them during training\r\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\r\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\r\n",
    "    optimizer = nlp.begin_training()\r\n",
    "    print(\"Training the model...\")\r\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\r\n",
    "    for i in range(n_iter):\r\n",
    "        losses = {}\r\n",
    "        # batch up the examples using spaCy's minibatch\r\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\r\n",
    "        for batch in batches:\r\n",
    "            texts, annotations = zip(*batch)\r\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\r\n",
    "                       losses=losses)\r\n",
    "        with textcat.model.use_params(optimizer.averages):\r\n",
    "            # evaluate on the dev data split off in load_data()\r\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\r\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\r\n",
    "              .format(losses['textcat'], scores['textcat_p'],\r\n",
    "                      scores['textcat_r'], scores['textcat_f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-portfolio",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RP37wXgjlfLJ",
    "outputId": "652c9944-1802-4414-cb35-2445a366f324"
   },
   "outputs": [],
   "source": [
    "# test the trained model\r\n",
    "test_text_neg = '\"we hated the service so much that we left without paying a tip\"'\r\n",
    "test_text_pos =\"We found the atmosphere warm and the food was delicious.\"\r\n",
    "doc_neg = nlp(test_text_neg)\r\n",
    "doc_neg.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-stroke",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FFsuJuA3liA5",
    "outputId": "236af509-24a9-46ff-a2e6-845a12a080d9"
   },
   "outputs": [],
   "source": [
    "doc_pos = nlp(test_text_pos)\r\n",
    "test_text_pos, doc_pos.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-guard",
   "metadata": {
    "id": "PUNQu1UhmGx5"
   },
   "outputs": [],
   "source": [
    "!mkdir review_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-blond",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTCI7y60rAy4",
    "outputId": "c787d9ca-2b5b-4260-e6a7-fa5aea678b54"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-nigeria",
   "metadata": {
    "id": "No__an2AsPtl"
   },
   "source": [
    "## Saving the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-fundamentals",
   "metadata": {
    "id": "Ql8aWdJ9sYP8"
   },
   "source": [
    "## Using the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-strand",
   "metadata": {
    "id": "56OCe4Vlq1MB"
   },
   "outputs": [],
   "source": [
    "nlp.to_disk('review_model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-management",
   "metadata": {
    "id": "raqb4aTRrW-l"
   },
   "outputs": [],
   "source": [
    "nlp2 = spacy.load('review_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-coaching",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXw0RNeMrgKh",
    "outputId": "7606b253-0e3d-457b-ef1e-3d3e6ecdce84"
   },
   "outputs": [],
   "source": [
    "text = \"we like coming here a lot\"\r\n",
    "doc = nlp2(text)\r\n",
    "print(text, doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-title",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUsRJtb0rpHx",
    "outputId": "f1c4983d-a3b5-48a7-8f5b-e1f306724289"
   },
   "outputs": [],
   "source": [
    "text = \"The environment was not great\"\r\n",
    "doc = nlp2(text)\r\n",
    "print(text, doc.cats)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "03d_SpaCy_Food_Reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
