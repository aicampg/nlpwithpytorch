{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intense-length",
   "metadata": {},
   "source": [
    "PyTorch `tensor` API is very similar to `numpy`. So if you are familiar with this math library, you should be at home with PyTorch's `tensor` functions. Here are a few areas where things might need to be reviewed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-repository",
   "metadata": {},
   "source": [
    "## Creating, Shaping, and referencing Arrays\n",
    "\n",
    "First, let's review the API for basic array manipulation in PyTorch\n",
    "\n",
    "Reference [1. PyTorch tensor types](https://pytorch.org/docs/stable/tensors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "junior-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "# Importing the libray & checking the version\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "published-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch vectors have a default type:\n",
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rough-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's change this to `float64`\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.get_default_dtype() \n",
    "\n",
    "# This won't work: \n",
    "# torch.set_defatult_dtype(torch.int) # won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-business",
   "metadata": {},
   "source": [
    "There's also this option: `torch.set_default_tensor_type(torch.DoubleTensor)`\n",
    "\n",
    "See documentation for details- https://pytorch.org/docs/stable/_modules/torch.html#set_default_tensor_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-origin",
   "metadata": {},
   "source": [
    "### Creating Torch Tensors using Python List format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "activated-respect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_array = torch.Tensor([[1,2,3],\n",
    "                             [4,5,6]])\n",
    "tensor_array # notice the 'dots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "framed-mumbai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.numel(tensor_array)) # \n",
    "print(torch.is_tensor(tensor_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polar-course",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00, 4.6444e-310,  0.0000e+00],\n",
       "        [4.6444e-310, 4.6444e-310, 4.6444e-310, 2.9644e-323],\n",
       "        [6.9481e-310, 6.9481e-310,  8.5267e+21, 6.9481e-310]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # creating tensor using only specified shape\n",
    "tensor_uninitialized = torch.Tensor(3, 4)\n",
    "tensor_uninitialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-company",
   "metadata": {},
   "source": [
    "### Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "promotional-minnesota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9743, 0.1624, 0.4889, 0.3946],\n",
       "        [0.8985, 0.7147, 0.6557, 0.1286],\n",
       "        [0.4564, 0.8626, 0.6585, 0.5904]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights of model parameters\n",
    "tensor_initialized = torch.rand(3, 4)\n",
    "tensor_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thirty-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_int = torch.tensor([5, 3]).type(torch.IntTensor) # on CPU --> see reference [1] for CPU & GPU tensor types\n",
    "# tensor_GPUfloat = torch.tensor([5, 3]).type(torch.cuda.FloatTensor) # will result in an error if CUDA library is not initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "general-multimedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2], dtype=torch.int16)\n",
      "tensor([1., 2.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "tensor_short = torch.ShortTensor([1, 2]) # directly instantiate a tensor of a type -- ensure you're only providing an int, not assuming implicit conversion\n",
    "tensor_float = torch.tensor([1.0, 2.0]).type(torch.half)\n",
    "print(tensor_short)\n",
    "print(tensor_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-newfoundland",
   "metadata": {},
   "source": [
    "### Filling with values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "killing-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10., 10.],\n",
      "        [10., 10.]])\n"
     ]
    }
   ],
   "source": [
    "tensor_fill = torch.full((2,2), fill_value=10, dtype=torch.float64) # try fill_value = 10., or use dtype=torch.float64\n",
    "print(tensor_fill)\n",
    "\n",
    "#What will this show?\n",
    "# tensor_fill.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "threatened-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor([[0, 0],\n",
      "        [1, 1],\n",
      "        [2, 2],\n",
      "        [3, 3],\n",
      "        [4, 4]])\n"
     ]
    }
   ],
   "source": [
    "tensor_of_ones = torch.ones([3,4], dtype=torch.int32)\n",
    "print(tensor_of_ones)\n",
    "\n",
    "tensor_of_zeros = torch.zeros_like(tensor_of_ones) # if you already have a shape and datatype of a tensor you want to replicate\n",
    "print(tensor_of_zeros)\n",
    "\n",
    "tensor_eye = torch.eye(5)\n",
    "print(tensor_eye)\n",
    "\n",
    "non_zero = torch.nonzero(tensor_eye)\n",
    "print(non_zero) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-heather",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "* `torch.tensor()` creates a copy of the unerlying data of the tensor\n",
    "* `torch.Tensor()` creates a view of the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abroad-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.tensor([[0, 1, 1, 0],\n",
    "                  [2, 2, 0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "generous-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([3, 4, 5, 10], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-blink",
   "metadata": {},
   "source": [
    "### Sparse matrix\n",
    "\n",
    "* Create a sparse tensor of shape (2,5) \n",
    "* In the example below, `sparse_tensor` has 2 rows and 3 columns values; remaining columns do not have values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "unlikely-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_tensor = torch.sparse_coo_tensor(i, v, [2, 5]) # in coordinate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "extra-implementation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 1, 1, 0],\n",
       "                       [2, 2, 0, 2]]),\n",
       "       values=tensor([ 3.,  4.,  5., 10.]),\n",
       "       size=(2, 5), nnz=4, dtype=torch.float32, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_tensor.data # every pytorch tensor has a underlying .data field - notice the structure is very different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "received-ranch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5., dtype=torch.float32)\n",
      "tensor(0., dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "print(sparse_tensor[1,0])\n",
    "print(sparse_tensor[0,0])\n",
    "\n",
    "# what will this be? \n",
    "#print(sparse_tensor[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-toddler",
   "metadata": {},
   "source": [
    "# Tensor operations \n",
    "1. In-place operation: `initial_tensor.fill_(n)` vs `initial_tensor.fill(n)`\n",
    "2. Out of place operation: `initial_tensor.add(n)` # added to every element but doesn't change `initial_tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "operational-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8466, 0.4982, 0.0671],\n",
      "        [0.4712, 0.0029, 0.5059]])\n",
      "tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.]])\n",
      "tensor([[15., 15., 15.],\n",
      "        [15., 15., 15.]])\n",
      "tensor([[20., 20., 20.],\n",
      "        [20., 20., 20.]])\n",
      "tensor([[4.4721, 4.4721, 4.4721],\n",
      "        [4.4721, 4.4721, 4.4721]])\n"
     ]
    }
   ],
   "source": [
    "init_tensor = torch.rand(2,3)\n",
    "print(init_tensor)\n",
    "\n",
    "# in-place operation\n",
    "init_tensor.fill_(10)\n",
    "print(init_tensor)\n",
    "\n",
    "init_tensor.add_(5)\n",
    "print(init_tensor)\n",
    "\n",
    "# out of place operation\n",
    "new_tensor = init_tensor.add(5)\n",
    "print(new_tensor)\n",
    "\n",
    "new_tensor.sqrt_()\n",
    "print(new_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "strange-lambda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(start=0, end=10, steps=11)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-sewing",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "general-practice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([4., 5., 6., 7.]), tensor([ 8.,  9., 10.]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_chunk = torch.chunk(x, 3, 0)\n",
    "tensor_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "reduced-pharmacology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 3., 4., 5.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = tensor_chunk[0] # tuple of tensor_chunk\n",
    "tensor2 = tensor_chunk[1]\n",
    "tensor3 = torch.tensor([3, 4, 5])\n",
    "torch.cat((tensor1, tensor2, tensor3), 0) # concatenate along a given dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "supreme-copper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  8., 10.],\n",
       "        [ 3.,  2.,  4.],\n",
       "        [ 2.,  3.,  5.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.Tensor([[10, 8, 10], [3, 2, 4], [2, 3, 5]])\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "traditional-costume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "likely-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  8., 10.,  3.,  2.,  4.,  2.,  3.,  5.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_tensor = random_tensor.view(9) # 3x3 is viewed as a 1-D 9 element tensor - needs to be compatible with the original tensor shape\n",
    "resized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "accessible-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10.,   8.,  10.,   3.,   2.,   4.,   2.,   3., 100.])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "random_tensor[2, 2] = 100\n",
    "print(resized_tensor) # original and resized tensors share the same underlying memory\n",
    "print(random_tensor.shape)\n",
    "print(resized_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-telephone",
   "metadata": {},
   "source": [
    "### Squeezing dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "valid-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 10.],\n",
       "         [  8.],\n",
       "         [ 10.]],\n",
       "\n",
       "        [[  3.],\n",
       "         [  2.],\n",
       "         [  4.]],\n",
       "\n",
       "        [[  2.],\n",
       "         [  3.],\n",
       "         [100.]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_unqueeze = torch.unsqueeze(random_tensor, 2)\n",
    "tensor_unqueeze # 3 x 3 x 1 - with the extra dimension we 'unsqueezed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "embedded-franklin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 15.],\n",
       "        [15., 15.],\n",
       "        [15., 15.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_transpose = torch.transpose(init_tensor, 0, 1) \n",
    "tensor_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-aggregate",
   "metadata": {},
   "source": [
    "### Sorting tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "domestic-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10.,   8.,  10.],\n",
       "        [  3.,   2.,   4.],\n",
       "        [  2.,   3., 100.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "accurate-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tensor, sorted_indices = torch.sort(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "boring-design",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  8.,  10.,  10.],\n",
       "        [  2.,   3.,   4.],\n",
       "        [  2.,   3., 100.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "saved-diamond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 2],\n",
       "        [1, 0, 2],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices # indices from the original tensor, but sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-family",
   "metadata": {},
   "source": [
    "### Floating operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "exceptional-keeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.2000,  3.2000,  2.3000, -1.0000], dtype=torch.float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float = torch.FloatTensor([-6.2, 3.2, 2.3, -1.0])\n",
    "tensor_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "stuffed-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.2000, 3.2000, 2.3000, 1.0000], dtype=torch.float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_abs = torch.abs(tensor_float)\n",
    "tensor_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-glenn",
   "metadata": {},
   "source": [
    "### Matrix operations\n",
    "\n",
    "0. addition (torch.add)\n",
    "1. division (torch.div)\n",
    "2. multiplication (torch.mul)\n",
    "3. Matrix-Vector multiplication (torch.mv)\n",
    "4. Matrix-matrix multiplication (torch.mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "alleged-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1 = torch.abs(torch.rand(2, 3))\n",
    "rand2 = torch.abs(torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "thorough-malpractice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1978, 0.6007, 0.6989],\n",
       "        [1.6855, 0.5637, 1.0774]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addition\n",
    "add1 = rand1 + rand2\n",
    "add1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "juvenile-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1978, 0.6007, 0.6989],\n",
       "        [1.6855, 0.5637, 1.0774]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add2 = torch.add(rand1, rand2)\n",
    "add2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-astronomy",
   "metadata": {},
   "source": [
    "1. Tensor Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "focal-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "#division\n",
    "tensor = torch.Tensor([[-1, -2, -3],\n",
    "                       [ 1,  2,  3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "large-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4286, 1.1765, 1.1111],\n",
       "        [0.7692, 0.8696, 0.9091]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_div = torch.div(tensor, tensor + 0.3)\n",
    "tensor_div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-chase",
   "metadata": {},
   "source": [
    "2. Vector multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "sixth-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 9.],\n",
       "        [1., 4., 9.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplication\n",
    "tensor_mul = torch.mul(tensor, tensor) \n",
    "tensor_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "explicit-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2000, -0.2000, -0.2000],\n",
       "        [ 1.0000,  2.0000,  2.0000]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_clamp = torch.clamp(tensor, min=-0.2, max=2)\n",
    "tensor_clamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-reflection",
   "metadata": {},
   "source": [
    "2. Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "conceptual-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.Tensor([1, 2])\n",
    "t2 = torch.Tensor([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "motivated-anderson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product = torch.dot(t1, t2)\n",
    "dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-intelligence",
   "metadata": {},
   "source": [
    "3. Multiply by multi-dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "incoming-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6]], dtype=torch.float64)\n",
    "vector = torch.Tensor([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "attempted-insured",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "affecting-wales",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "continued-equivalent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 17.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_vector = torch.mv(matrix, vector)\n",
    "matrix_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-danish",
   "metadata": {},
   "source": [
    "4. Matrix-Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ongoing-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_matrix = torch.Tensor([[10, 30],\n",
    "                               [20, 0],\n",
    "                               [0, 50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "closed-excellence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 50., 180.],\n",
       "        [140., 420.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_mul = torch.mm(matrix, another_matrix)\n",
    "matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-carbon",
   "metadata": {},
   "source": [
    "5. Other operations: argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "geographic-dimension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(matrix_mul, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "palestinian-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(matrix_mul, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-distinction",
   "metadata": {},
   "source": [
    "### Converting to Numpy and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "invalid-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "charitable-guinea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9392, 0.3672, 0.2916],\n",
       "        [0.5239, 0.0381, 0.6503],\n",
       "        [0.2986, 0.8337, 0.2599],\n",
       "        [0.0639, 0.4277, 0.6613]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(4, 3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "constant-capture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm it's a torch tensor\n",
    "type(tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "alternative-aviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93918337, 0.36717894, 0.29164179],\n",
       "       [0.52393005, 0.03809374, 0.65026695],\n",
       "       [0.29860565, 0.83371833, 0.25987739],\n",
       "       [0.06392023, 0.42767944, 0.66132197]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_from_tensor = tensor.numpy()\n",
    "numpy_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "illegal-shannon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "float64\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(tensor.dtype)\n",
    "print(numpy_from_tensor.dtype)\n",
    "print(type(numpy_from_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-financing",
   "metadata": {},
   "source": [
    "They share the same underlying memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "abandoned-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+02, 3.67178943e-01, 2.91641786e-01],\n",
       "       [5.23930051e-01, 3.80937440e-02, 6.50266950e-01],\n",
       "       [2.98605654e-01, 8.33718329e-01, 2.59877393e-01],\n",
       "       [6.39202272e-02, 4.27679439e-01, 6.61321973e-01]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_from_tensor[0, 0] = 100.0\n",
    "numpy_from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "incorporate-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+02, 3.6718e-01, 2.9164e-01],\n",
       "        [5.2393e-01, 3.8094e-02, 6.5027e-01],\n",
       "        [2.9861e-01, 8.3372e-01, 2.5988e-01],\n",
       "        [6.3920e-02, 4.2768e-01, 6.6132e-01]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "colored-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.],\n",
       "       [ 10.,  20.,  30.],\n",
       "       [100., 200., 300.]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arr = np.array([[1.0, 2.0, 3.0],\n",
    "                      [10, 20., 30.],\n",
    "                      [100, 200, 300.]])\n",
    "\n",
    "numpy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "located-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   2.,   3.],\n",
       "        [ 10.,  20.,  30.],\n",
       "        [100., 200., 300.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_numpy = torch.from_numpy(numpy_arr)\n",
    "tensor_from_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "primary-degree",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "assisted-finger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "robust-theory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.],\n",
       "        [ 10.,  20.,  30.],\n",
       "        [100., 200., 300.]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_numpy[0] = 1\n",
    "tensor_from_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "charged-inside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1.],\n",
       "       [ 10.,  20.,  30.],\n",
       "       [100., 200., 300.]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-garage",
   "metadata": {},
   "source": [
    "Modifications in the numpy array carry to the torch tensor array, & back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "extra-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 8])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array_one= np.array([4, 8])\n",
    "np_array_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "instrumental-textbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 8])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_array_one = torch.as_tensor(np_array_one)\n",
    "tensor_from_array_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "political-christian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array_one[1] = 5\n",
    "np_array_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "latest-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_array_one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-picture",
   "metadata": {},
   "source": [
    "To create a separate copy of the numpy array, use `torch.tensor` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "relative-choice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array_two = np.array([2, 2])\n",
    "np_array_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "undefined-mixture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_array_two = torch.tensor(np_array_two)\n",
    "tensor_from_array_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "radical-person",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array_two[1] = 4\n",
    "np_array_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "colonial-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_from_array_two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-recovery",
   "metadata": {},
   "source": [
    "## PyTorch, CUDA, and GPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-spank",
   "metadata": {},
   "source": [
    "* PyTorch Tensors have been architected to make optimal use of GPUs for massively parallel computations. \n",
    "* Initially used for video & graphics processing, now widely used for big data & ML operations\n",
    "* Training on massive parallel arch can be sped up by 10-15x\n",
    "* NV created CUDA application programming interface for general purpose use of GPUs beyond graphics\n",
    "* Any FW support for GPUs has to integrate with the CUDA platform - Compute Unified Device Architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-salon",
   "metadata": {},
   "source": [
    "PyTorch Support for CUDA\n",
    "* Dev can write CUDA compliant code\n",
    "* Understood by CUDA aware FW\n",
    "* Tensors need to be instantiated on the GPU for automatic speed up\n",
    "* Use `torch.cuda` for CUDA operations\n",
    "* Special Tensor types for CUDA,e x. `torch.cuda.FloatTensor` \n",
    "* Use `torch.cuda.device` context manager tracks selected GPU and creates tensors on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-regulation",
   "metadata": {},
   "source": [
    "All operations are on the same device \n",
    "* Cross GPU ops not allowed \n",
    "* Exceptions: Copy operations: `copy_()`, `to()`, `cuda()`\n",
    "* GPU ops are asynchronous by default\n",
    "* Enquied to particular device and invisible to teh user- FIFO\n",
    "* Copy from one device to another (CPU->GPU, or GPU->GPU)\n",
    "* use an env variable for synch, for debugging; `CUDA_LAUNCH_BLOCKING = 1` for error handling and stack tracing, usu not available in async operation\n",
    "* Functions, such as `to()`, `copy()` allow non-blocking argument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-score",
   "metadata": {},
   "source": [
    "Device agnostic code\n",
    "* explicitly handles GPU or CPU cases\n",
    "* common pattern is to use argparse to read user arguments\n",
    "* code can be invoked with runtime flag to enable or disable runtime flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-constant",
   "metadata": {},
   "source": [
    "Tensors make up our DIRECTED ACYCLIC Computation Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-microphone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
